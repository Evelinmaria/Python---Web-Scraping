{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "web_scraping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tjoh2gEvs_jl"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_web(url):\n",
        "  response = requests.get(url)\n",
        "\n",
        "  if response.status_code != 200:\n",
        "    print(\"Failed to load page {}\".format(url))\n",
        "  \n",
        "  doc = BeautifulSoup(response.text, 'html.parser')\n",
        "  return doc"
      ],
      "metadata": {
        "id": "GyUwUUpp6_J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_topics(url):\n",
        "  parsed_data = download_web(url)\n",
        "  select_topic = \"f3 lh-condensed mb-0 mt-1 Link--primary\"\n",
        "  topic_title = parsed_data.find_all('p',{'class':select_topic})\n",
        "\n",
        "  select_topic_desc = \"f5 color-fg-muted mb-0 mt-1\"\n",
        "  topic_desc = parsed_data.find_all('p',{'class':select_topic_desc})\n",
        "\n",
        "  select_topic_url = \"no-underline flex-1 d-flex flex-column\"\n",
        "  topic_url = parsed_data.find_all('a',{'class':select_topic_url})\n",
        "\n",
        "  All_topic_titles = []\n",
        "  All_topic_desc = []\n",
        "  All_topic_urls = []\n",
        "\n",
        "  for tag in topic_title:\n",
        "    All_topic_titles.append(tag.text)\n",
        "  for tag in topic_desc:\n",
        "    All_topic_desc.append(tag.text.strip())\n",
        "  for tag in topic_url:\n",
        "    All_topic_urls.append('https://github.com' + tag['href'])\n",
        " \n",
        "  return All_topic_titles, All_topic_desc, All_topic_urls\n"
      ],
      "metadata": {
        "id": "UlUWRE3vy6md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_star_count(stars_str):\n",
        "    stars_str = stars_str.strip()\n",
        "    if ',' in stars_str:\n",
        "        stars_str = stars_str.replace(',', '')\n",
        "    stars_str = int(stars_str)\n",
        "    return(stars_str)"
      ],
      "metadata": {
        "id": "I276o2i0HvIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_repo_info(repo_tag, star_tag):\n",
        "    a_tags = repo_tag.find_all('a')\n",
        "    username = a_tags[0].text.strip()\n",
        "    repo_name = a_tags[1].text.strip()\n",
        "    repo_url = \"https://github.com\" + a_tags[1]['href']\n",
        "    stars = parse_star_count(star_tag['title'])\n",
        "    return username, repo_name, stars, repo_url"
      ],
      "metadata": {
        "id": "WGjlvcLmHjbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_repo_details(topic_url):\n",
        "  topic_data = download_web(topic_url)\n",
        "\n",
        "  # get the parent tag (h3) which has the required tags\n",
        "  h3_selector = \"f3 color-fg-muted text-normal lh-condensed\"\n",
        "  repo_tags = topic_data.find_all('h3', class_=h3_selector)\n",
        "\n",
        "  # get the tag that contains stars info\n",
        "  stars_selector = \"Counter js-social-count\"\n",
        "  star_tags = topic_data.find_all('span', class_=stars_selector)\n",
        "\n",
        "  topic_repos_dict = {\n",
        "        'username': [],\n",
        "        'repo_name': [],\n",
        "        'stars': [],\n",
        "        'repo_url': []\n",
        "    }\n",
        "\n",
        "  for i in range(len(repo_tags)):\n",
        "        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
        "        topic_repos_dict['username'].append(repo_info[0])\n",
        "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
        "        topic_repos_dict['stars'].append(repo_info[2])\n",
        "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
        "\n",
        "  topic_repos_df = pd.DataFrame(topic_repos_dict)\n",
        "\n",
        "  return topic_repos_df"
      ],
      "metadata": {
        "id": "CaX4EPN9Eo9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_web(url):\n",
        "  topic_details = scrape_topics(url)\n",
        "  topic_dict = {\n",
        "        'title': topic_details[0],\n",
        "        'description': topic_details[1],\n",
        "        'url': topic_details[2]\n",
        "    }\n",
        "  topic_df = pd.DataFrame(topic_dict)\n",
        "  all_df = [topic_df]\n",
        "\n",
        "  for url in topic_dict['url']:\n",
        "    data = get_repo_details(url)\n",
        "\n",
        "  return all_df"
      ],
      "metadata": {
        "id": "iMJ8lhAoyh6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  url = \"https://github.com/topics\"\n",
        "  topic = scrape_web(url)\n",
        "  #print(topic)\n",
        "\n",
        "  os.makedirs(\"scraped data\", exist_ok=True)\n",
        "\n",
        "  topic_titles = topic[0]['title']\n",
        "\n",
        "  for i in range(len(topic)):\n",
        "      if i == 0:\n",
        "          topic[i].to_csv(\"scraped data/{}\".format(\"allTopics.csv\"), index = None)\n",
        "      else:\n",
        "          topic[i].to_csv(\"scraped data/{}\".format(topic_titles[i-1] + \".csv\"), index = None)\n",
        "if __name__=='__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "civ5nY5Qxy1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TCRGRs3ixzBt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}